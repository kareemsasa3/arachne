services:
  # Nginx reverse proxy
  nginx:
    image: nginx:alpine
    container_name: arachne-nginx
    environment:
      - DOMAIN_NAME=${DOMAIN_NAME}
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/letsencrypt:ro
      - ./nginx/certbot/www:/var/www/certbot:ro
      - ./logs/nginx:/var/log/nginx
      - ./nginx/conf.d/default.conf.template:/tmp/default.conf.template:ro
    depends_on:
      - ai
      - scraper
      - web
    restart: unless-stopped
    command: >
      /bin/sh -c "sed 's/__DOMAIN_NAME__/'\"$DOMAIN_NAME\"'/g' /tmp/default.conf.template > /tmp/default.conf && nginx -g 'daemon off;'"
    networks:
      - ${DOCKER_NETWORK_NAME:-arachne-network}

  # Web Console - Scraper console
  web:
    image: ${WEB_IMAGE:-ghcr.io/your-username/personal-website/web:latest}
    container_name: arachne-web
    environment:
      - NODE_ENV=${WEB_NODE_ENV:-production}
      - PORT=${WEB_PORT:-3000}
      - AI_URL=${AI_URL:-http://ai:3001}
      - SCRAPER_API_URL=${SCRAPER_API_URL:-http://scraper:8080}
      - NEXT_PUBLIC_SCRAPER_API_URL=${NEXT_PUBLIC_SCRAPER_API_URL:-http://scraper:8080}
    depends_on:
      - ai
      - scraper
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-arachne-network}

  # AI service - AI microservice
  ai:
    image: ${AI_IMAGE:-ghcr.io/your-username/personal-website/ai:latest}
    container_name: arachne-ai
    environment:
      - NODE_ENV=${AI_NODE_ENV:-production}
      - PORT=${AI_PORT:-3001}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LOG_LEVEL=${AI_LOG_LEVEL:-info}
      - ENABLE_METRICS=${AI_ENABLE_METRICS:-true}
      - RATE_LIMIT_WINDOW_MS=${AI_RATE_LIMIT_WINDOW_MS:-900000}
      - RATE_LIMIT_MAX_REQUESTS=${AI_RATE_LIMIT_MAX_REQUESTS:-100}
      - SCRAPER_URL=${SCRAPER_URL:-http://scraper:8080}
      - SCRAPER_API_TOKEN=${SCRAPER_API_TOKEN:-}
      - PROFILE_CONTEXT_PATH=/app/profile/profile.md
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-arachne-network}
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:3001/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Scraper - Web scraping service
  scraper:
    image: ${SCRAPER_IMAGE:-ghcr.io/your-username/personal-website/scraper:latest}
    container_name: arachne-scraper
    environment:
      - SCRAPER_REDIS_ADDR=${SCRAPER_REDIS_ADDR:-redis:6379}
      - SCRAPER_REDIS_DB=${SCRAPER_REDIS_DB:-0}
      - SCRAPER_ENABLE_METRICS=${SCRAPER_ENABLE_METRICS:-true}
      - SCRAPER_ENABLE_LOGGING=${SCRAPER_ENABLE_LOGGING:-true}
      - SCRAPER_LOG_LEVEL=${SCRAPER_LOG_LEVEL:-info}
      - SCRAPER_MAX_CONCURRENT=${SCRAPER_MAX_CONCURRENT:-5}
      - SCRAPER_REQUEST_TIMEOUT=${SCRAPER_REQUEST_TIMEOUT:-120s}
      - SCRAPER_TOTAL_TIMEOUT=${SCRAPER_TOTAL_TIMEOUT:-180s}
      - SCRAPER_USE_HEADLESS=${SCRAPER_USE_HEADLESS:-true}
      - SCRAPER_USER_AGENT=${SCRAPER_USER_AGENT:-Mozilla/5.0 (compatible; ArachneBot/1.0)}
      - SCRAPER_RATE_LIMIT=${SCRAPER_RATE_LIMIT:-2}
      - SCRAPER_RATE_LIMIT_WINDOW=${SCRAPER_RATE_LIMIT_WINDOW:-1s}
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-arachne-network}
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:8080/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis - Required by Arachne for job storage
  redis:
    image: redis:7-alpine
    container_name: arachne-redis
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory ${REDIS_MAX_MEMORY:-512mb} --maxmemory-policy ${REDIS_MAX_MEMORY_POLICY:-allkeys-lru}
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-arachne-network}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Commander - Optional UI for Redis management
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: arachne-redis-commander
    environment:
      - REDIS_HOSTS=local:redis:${REDIS_PORT:-6379}
    depends_on:
      - redis
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-arachne-network}

networks:
  arachne-network:
    driver: bridge

volumes:
  redis_data:
    driver: local
