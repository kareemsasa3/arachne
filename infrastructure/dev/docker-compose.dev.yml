# Development Docker Compose
# Usage: docker compose -f docker-compose.yml -f dev/docker-compose.dev.yml up --build
#
# Run from: infrastructure/
#
# PREREQUISITE (now handled in-container): Containers install their own node_modules.
# You no longer need host-installed node_modules, but you can keep them if you want.

services:
  # AI Backend - Node.js with nodemon hot reload
  ai:
    container_name: portfolio-ai-dev
    build:
      context: ../services/ai
      dockerfile: Dockerfile.dev
    environment:
      - NODE_ENV=development
      - PORT=3001
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - SCRAPER_URL=http://scraper:8080
      - SCRAPER_API_TOKEN=${SCRAPER_API_TOKEN:-}
      - PROFILE_CONTEXT_PATH=/app/profile/profile.md
    volumes:
      - ../services/ai:/app:rw
      - ../profile/profile.md:/app/profile/profile.md:ro
      - ai-node_modules:/app/node_modules
    command: sh -c "npm install && npm run dev"
    ports:
      - "3001:3001"

  # Arachne - Go with Air hot reload
  scraper:
    container_name: portfolio-scraper-dev
    build:
      context: ../services/scraper
      dockerfile: ../../infrastructure/dev/arachne.Dockerfile
    environment:
      - SCRAPER_REDIS_ADDR=redis:6379
      - SCRAPER_REDIS_DB=0
      - SCRAPER_ENABLE_METRICS=true
      - SCRAPER_ENABLE_LOGGING=true
      - SCRAPER_LOG_LEVEL=debug
      - SCRAPER_MAX_CONCURRENT=3
      - SCRAPER_REQUEST_TIMEOUT=40s
      - SCRAPER_TOTAL_TIMEOUT=60s
      - SCRAPER_USE_HEADLESS=true
      - SCRAPER_MAX_CONTENT_BYTES=200000
      - SCRAPER_HEADLESS_NO_SANDBOX=true
    volumes:
      - ../services/scraper:/app:rw
      # Path relative to CWD (infrastructure/), not to this file
      - ./dev/arachne.air.toml:/etc/air/air.toml:ro
    command: air -c /etc/air/air.toml
    shm_size: "1gb"
    ports:
      - "8080:8080"

  # Arachne UI - Next.js dev server with Turbopack
  web:
    container_name: portfolio-web-dev
    build:
      context: ../services/web
      dockerfile: Dockerfile.dev
    environment:
      - NODE_ENV=development
      - PORT=3002
      # Server-side URLs (internal Docker network)
      - AI_URL=http://ai:3001
      - SCRAPER_API_URL=http://scraper:8080
      # Client-side URL (browser goes through nginx)
      - NEXT_PUBLIC_SCRAPER_API_URL=/api/arachne
    volumes:
      - ../services/web:/app:rw
      - web-node_modules:/app/node_modules
    command: sh -c "npm install && npm run dev -- --hostname 0.0.0.0 --port 3002"
    depends_on:
      - ai
      - scraper
    ports:
      - "3002:3002"

  # Redis Commander - disabled by default, enable with --profile monitoring
  redis-commander:
    profiles: ["monitoring"]

  # Nginx - reverse proxy for all services
  nginx:
    container_name: portfolio-nginx-dev
    volumes:
      # Paths relative to CWD (infrastructure/), not to this file
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d/default.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "80:80"
    depends_on:
      - ai
      - scraper
      - web

volumes:
  ai-node_modules:
  web-node_modules:
